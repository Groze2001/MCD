{"cells":[{"cell_type":"markdown","source":["<font size=\"5\">\n"," <div class=\"alert alert-block alert-info\"> <b>Week 7: Deep Neural Networks (DNNs)<b>\n","     </div>\n","</font>\n","\n","      \n","    \n","  <font size=\"4\"> MCD - An√°lise de S√©ries Temporais e Previs√£o </font>\n","  \n","  \n","  <font size=\"3\"> **Filipe R. Ramos** </font>\n","      \n","   \n","  <font size=\"3\"> *frjrs@iscte-iul.pt* </font>  \n","   \n","    \n","  <font size=\"3\">ISCTE-IUL </font>"],"metadata":{"id":"_5HidhS9KQgu"},"id":"_5HidhS9KQgu"},{"cell_type":"markdown","source":["<font size=\"5\">\n","    <div class=\"alert alert-warning\" role=\"alert\"> -- Deep Neural Networks -- </div> </font>\n","\n","## **Agenda**\n","\n","1. **Deep Neural Networks (DNNs): Introduction**\n","\n","2. **Recurrent Neural Networks (RNNs)**\n","\n","3. **Gated recurrent units (GRUs)**\n","\n","4. **Long Short-Term Memory (LSTM)**\n","---------------------\n","\n","\n","## **References**\n","- [Chollet, F. (2017)](https://sourestdeeds.github.io/pdf/Deep%20Learning%20with%20Python.pdf)\n","\n","- [Haykin, S. (2009)](https://lps.ufrj.br/~caloba/Livros/Haykin2009.pdf)\n","\n","\n","- [Introduction to Machine Learning with Python  book](https://learning.oreilly.com/library/view/introduction-to-machine/9781449369880/)\n","\n","---------------------\n","\n","\n","<font size=\"5\"> <div class=\"alert alert-success\" role=\"alert\"> **Objetivos** </div></font>\n","\n","- Entender o funcionamento b√°sico de diferentes RNNs (SimpleRNN, LSTM, GRU).\n","- Observar sinais de overfitting durante o treino.\n","- Interpretar as curvas de perda (loss curves) de treino e valida√ß√£o."],"metadata":{"id":"SkrP_DZnKUVc"},"id":"SkrP_DZnKUVc"},{"cell_type":"markdown","id":"6e861697","metadata":{"id":"6e861697"},"source":["# **Import libraries**"]},{"cell_type":"code","execution_count":null,"id":"e3ea32c2","metadata":{"ExecuteTime":{"end_time":"2024-10-27T22:37:20.074716Z","start_time":"2024-10-27T22:37:20.071865Z"},"id":"e3ea32c2"},"outputs":[],"source":["### bibliotecas\n","\n","\n","# Import necessary libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import SimpleRNN, Dense, LSTM, GRU\n","from tensorflow.keras.optimizers import SGD, Adam\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"markdown","source":["# **Define Functions**"],"metadata":{"id":"tDrw64WNLHgj"},"id":"tDrw64WNLHgj"},{"cell_type":"code","source":["# Define ts_train_test_normalize function\n","def ts_train_test_normalize(data, seq_length, test_size):\n","    \"\"\"\n","    Prepares the time series data for training and testing.\n","\n","    Args:\n","        data (np.ndarray): The time series data.\n","        seq_length (int): The length of the input sequence for the RNN.\n","        test_size (int): The number of data points to use for testing.\n","\n","    Returns:\n","        tuple: X_train, y_train, X_test, scaler\n","    \"\"\"\n","    scaler = MinMaxScaler(feature_range=(0, 1))\n","    data = scaler.fit_transform(data.reshape(-1, 1))\n","\n","    X, y = [], []\n","    for i in range(seq_length, len(data)):\n","        X.append(data[i - seq_length:i, 0])\n","        y.append(data[i, 0])\n","\n","    X = np.array(X)\n","    y = np.array(y)\n","\n","    X_train = X[:-test_size]\n","    y_train = y[:-test_size]\n","    X_test = X[-test_size:]\n","\n","    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n","\n","    return X_train, y_train, X_test, scaler"],"metadata":{"id":"yRA_5twnLIPi"},"id":"yRA_5twnLIPi","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Generate Data**\n","\n","Vamos criar uma s√©rie temporal simples para treino."],"metadata":{"id":"UAgRREq9MyWN"},"id":"UAgRREq9MyWN"},{"cell_type":"code","execution_count":null,"id":"206cbbfe","metadata":{"ExecuteTime":{"end_time":"2024-10-27T22:43:17.847712Z","start_time":"2024-10-27T22:43:17.664011Z"},"id":"206cbbfe"},"outputs":[],"source":["# Vamos criar uma s√©rie temporal simples para treino\n","def generate_data(n_samples=1000, noise=0.1):\n","    X = np.linspace(0, 100, n_samples)\n","    y = np.sin(X) + noise * np.random.randn(n_samples)\n","    return X, y\n","\n","X, y = generate_data()\n","\n","# Visualizar os primeiros dados\n","plt.plot(X, y)\n","plt.title(\"S√©rie temporal simulada\")\n","plt.xlabel(\"Tempo\")\n","plt.ylabel(\"Valor\")\n","plt.show()\n","\n","\n"]},{"cell_type":"markdown","source":["# **Data Preparation**\n","Modelo sequencial com uma camada RNN simples"],"metadata":{"id":"ypIF9GDKOIdu"},"id":"ypIF9GDKOIdu"},{"cell_type":"code","source":["def create_sequences(X, y, seq_length=10):\n","    Xs, ys = [], []\n","    for i in range(len(X) - seq_length):\n","        Xs.append(y[i:i+seq_length])\n","        ys.append(y[i+seq_length])\n","    return np.array(Xs), np.array(ys)\n","\n","seq_length = 10\n","X_seq, y_seq = create_sequences(X, y, seq_length)\n","\n","# Ajustar formato para (amostras, timesteps, features)\n","X_seq = X_seq[..., np.newaxis]\n","\n","# Dividir em treino e teste\n","split = int(0.8 * len(X_seq))\n","X_train, X_test = X_seq[:split], X_seq[split:]\n","y_train, y_test = y_seq[:split], y_seq[split:]\n"],"metadata":{"id":"jEI8ciyvPw5r"},"id":"jEI8ciyvPw5r","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Define the RNN Model**"],"metadata":{"id":"EqHnce2SAyGc"},"id":"EqHnce2SAyGc"},{"cell_type":"code","execution_count":null,"id":"ab1bf561","metadata":{"ExecuteTime":{"end_time":"2024-10-27T22:44:25.000012Z","start_time":"2024-10-27T22:44:24.983606Z"},"id":"ab1bf561"},"outputs":[],"source":["# Fun√ß√£o gen√©rica para criar modelos RNN, LSTM ou GRU\n","def build_model(model_type='SimpleRNN', seq_length=10, units=20):\n","    model = Sequential()\n","    if model_type == 'SimpleRNN':\n","        model.add(SimpleRNN(units, activation='tanh', input_shape=(seq_length, 1)))\n","    elif model_type == 'LSTM':\n","        model.add(LSTM(units, activation='tanh', input_shape=(seq_length, 1)))\n","    elif model_type == 'GRU':\n","        model.add(GRU(units, activation='tanh', input_shape=(seq_length, 1)))\n","    else:\n","        raise ValueError(\"model_type deve ser 'SimpleRNN', 'LSTM' ou 'GRU'\")\n","\n","    model.add(Dense(1))\n","    model.compile(optimizer='adam', loss='mse')\n","    return model\n","\n","\n","# Escolher modelo\n","# Definir o tipo de RNN a utilizar\n","model_type = 'SimpleRNN'  # <- Pode mudar para 'LSTM' ou 'GRU'\n","model = build_model(model_type=model_type, seq_length=seq_length)\n","\n","\n","# Mostrar resumo do modelo\n","model.summary()\n","\n"]},{"cell_type":"markdown","source":["#**Train and Evaluate the Model**"],"metadata":{"id":"qwDshYA_FkLS"},"id":"qwDshYA_FkLS"},{"cell_type":"code","execution_count":null,"id":"e8a335b8","metadata":{"id":"e8a335b8"},"outputs":[],"source":["# TREINAR MODELO\n","early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","history = model.fit(\n","    X_train, y_train,\n","    epochs=100,\n","    batch_size=32,\n","    validation_split=0.2,\n","    callbacks=[early_stopping]\n",")\n","\n","# Assuming 'y' from generate_data function is your time series data and you want to use the same test set size as in LSTM_model\n","_, _, X_test, _ = ts_train_test_normalize(y, 5, 2)\n","# Get y_test from the original 'y' data\n","y_test = y[-len(X_test):]\n","\n","# Now scale y_test using the same scaler used for training\n","y_test = sc.transform(y_test.reshape(-1, 1)).ravel() # Scale y_test and flatten it\n","\n","\n","# AVALIAR MODELO\n","loss = model.evaluate(X_test, y_test)\n","print(f\"Loss no conjunto de teste: {loss:.4f}\")\n"]},{"cell_type":"markdown","source":["#**Visualise Loss Curves**"],"metadata":{"id":"FWc7QYWQGKEK"},"id":"FWc7QYWQGKEK"},{"cell_type":"code","source":["# VISUALIZAR CURVAS DE PERDA\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.legend()\n","plt.title(f'Curvas de Perda - {model_type}')\n","plt.xlabel('√âpocas')\n","plt.ylabel('Loss')\n","plt.show()"],"metadata":{"id":"qIZSEj0LGVCB"},"id":"qIZSEj0LGVCB","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Nota Informativa - Interpreta√ß√£o das Curvas de Perda (Train e Validation)\n","\n","A imagem mostra as curvas de **Train Loss** (Perda no Treino) e **Validation Loss** (Perda na Valida√ß√£o) ao longo das √©pocas de um modelo **SimpleRNN** para previs√£o de s√©ries temporais.\n","\n","\n","üîµ Train Loss (Linha azul):\n","- Representa o erro do modelo nos dados de treino.\n","\n","üü† Validation Loss (Linha laranja):\n","- Representa o erro nos dados de valida√ß√£o, que n√£o foram utilizados no treino.\n","\n","\n","---\n","\n","## **1. Comportamento Ideal**\n","- ‚úÖ Ambas as curvas (treino e valida√ß√£o) decrescem e estabilizam em um valor **baixo e similar**.  \n","- **Exemplo**: Se a perda final for ~0.1 para ambas, o modelo generaliza bem.\n","\n","---\n","\n","## **2. Problemas Comuns e Solu√ß√µes**\n","\n","### **üìâ Overfitting (Sobreajuste)**\n","- **Sinal**:  \n","  - *Train Loss* ‚ÜòÔ∏è continua a diminuir.  \n","  - *Validation Loss* ‚ÜóÔ∏è aumenta ap√≥s certa √©poca.  \n","- **Causa**: Modelo memoriza os dados de treino.  \n","- **Solu√ß√£o**:  \n","  - Regulariza√ß√£o (Dropout, L2).  \n","  - *Early stopping* (parada antecipada).  \n","\n","### **üìà Underfitting (Subajuste)**\n","- **Sinal**:  \n","  - Ambas as curvas altas (ex.: >0.5) e n√£o convergem.  \n","- **Causa**: Modelo muito simples ou treino insuficiente.  \n","- **Solu√ß√£o**:  \n","  - Aumentar unidades/camadas RNN.  \n","  - Treinar por mais √©pocas.  \n","\n","### **üåÄ Instabilidade**\n","- **Sinal**: Oscila√ß√µes bruscas nas curvas.  \n","- **Causa**: *Learning rate* alto ou *batch size* pequeno.  \n","- **Solu√ß√£o**:  \n","  - Reduzir taxa de aprendizagem.  \n","  - Aumentar *batch size*.  \n","\n","---\n","\n","## **3. Observa√ß√µes para S√©ries Temporais**\n","- **Valida√ß√£o**: Usar divis√£o temporal (ex.: dados recentes para valida√ß√£o).  \n","- **Early Stopping**: Ativar se a *Validation Loss* n√£o melhora em N √©pocas.  \n","\n","---\n","\n","## **4. Exemplo Pr√°tico (Imagem)**\n","- Se *Validation Loss* ‚ÜóÔ∏è ap√≥s certa √©poca ‚Üí **Overfitting**.  \n","- Se ambas ‚ÜòÔ∏è lentamente ‚Üí Pode precisar de mais √©pocas.  \n","\n","**A√ß√£o Recomendada**:  \n","```python\n","# C√≥digo para early stopping (exemplo no Keras)\n","from tensorflow.keras.callbacks import EarlyStopping\n","early_stop = EarlyStopping(monitor='val_loss', patience=5)\n","model.fit(..., callbacks=[early_stop])\n","```\n","---\n","\n","‚úÖ Em geral:\n","\n","- Queremos perdas baixas e curvas relativamente est√°veis.\n","- A dist√¢ncia entre a perda de treino e a perda de valida√ß√£o deve ser pequena.\n","- O comportamento das curvas ajuda a decidir se √© necess√°rio alterar o modelo, os hiperpar√¢metros ou os dados.\n","\n"],"metadata":{"id":"qPUqxtnQNBzi"},"id":"qPUqxtnQNBzi"},{"cell_type":"markdown","source":["---------------------------------"],"metadata":{"id":"jKMEdtbUNz7i"},"id":"jKMEdtbUNz7i"},{"cell_type":"markdown","source":["-----------------------------"],"metadata":{"id":"b_1gy22jNxES"},"id":"b_1gy22jNxES"},{"cell_type":"markdown","source":["## **Exerc√≠cio:**\n","\n","----------------------\n","\n","\n","**1. Modificar o tipo de modelo**\n","  \n","  - Experimente usar 'LSTM' ou 'GRU' em vez de 'SimpleRNN'.\n","  - Compare as curvas de perda e o valor final da loss.\n","\n","\n","- **Quest√£o:** Qual das arquiteturas teve melhor capacidade de generaliza√ß√£o?\n","\n","----------------------\n","\n","**2. Alterar o n√∫mero de unidades**\n","\n"," - Aumente `units` de 20 para 50.\n","\n"," - Observe o impacto nas curvas de treino e valida√ß√£o.\n","\n","\n","\n","- **Quest√£o:** O modelo ficou mais sujeito a overfitting?\n","\n","----------------------\n","\n","**3. Alterar o tamanho do `batch`**\n","\n"," - Experimente `batch_size` de 64 ou 128.\n"," - Observe o impacto na estabilidade e velocidade do treino.\n","\n","\n","- **Quest√£o:** O treino ficou mais r√°pido? Mais est√°vel?\n","\n","----------------------\n","\n","**4. Aumentar o ru√≠do nos dados**\n","\n"," - Aumente o par√¢metro noise da fun√ß√£o `generate_data`..\n"," - Observe como √© que o modelo lida com dados mais \"ru√≠do\".\n","\n","\n","- **Quest√£o:** Alguma arquitetura (SimpleRNN, LSTM ou GRU) lida melhor com mais ru√≠do?\n","\n","\n","----------------------\n","\n","\n","# **Notas Finais**\n","- Sinais de overfitting: perda de valida√ß√£o come√ßa a aumentar enquanto a perda de treino continua a diminuir.\n","\n","- EarlyStopping √© uma t√©cnica para mitigar overfitting automaticamente.\n","\n","\n","\n","----------------------\n","\n","\n","# **Desafio**\n","- Como aumentar o n√∫mero de camadas na rede neuronal?\n"],"metadata":{"id":"lxqT0mvtUIIH"},"id":"lxqT0mvtUIIH"}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"nbTranslate":{"displayLangs":["*"],"hotkey":"alt-t","langInMainMenu":true,"sourceLang":"en","targetLang":"fr","useGoogleTranslate":true},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[{"file_id":"1MlW8Hex7pzmJNsEuBUXT9a8FpPj7PVy0","timestamp":1743997763788},{"file_id":"1m0VxHKkMXBmNjujdJbrVed1GtyEdTTyN","timestamp":1743992243721},{"file_id":"1hGCyxoEf7OJhaU_xleLDgWwLUqBSPZaM","timestamp":1743981003487},{"file_id":"1nTp7dsMoLLQNps1nVYgt9PYC20vL-unI","timestamp":1743980610224},{"file_id":"112LDK1eqwNEtWTeiFWq41upNTGJsChMn","timestamp":1730236801068}]}},"nbformat":4,"nbformat_minor":5}