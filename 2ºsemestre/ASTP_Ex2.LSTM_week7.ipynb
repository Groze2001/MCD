{"cells":[{"cell_type":"markdown","source":["<font size=\"5\">\n"," <div class=\"alert alert-block alert-info\"> <b>Week 7: Deep Neural Networks (DNNs)<b>\n","     </div>\n","</font>\n","\n","      \n","    \n","  <font size=\"4\"> MCD - Análise de Séries Temporais e Previsão </font>\n","  \n","  \n","  <font size=\"3\"> **Filipe R. Ramos** </font>\n","      \n","   \n","  <font size=\"3\"> *frjrs@iscte-iul.pt* </font>  \n","   \n","    \n","  <font size=\"3\">ISCTE-IUL </font>"],"metadata":{"id":"_5HidhS9KQgu"},"id":"_5HidhS9KQgu"},{"cell_type":"markdown","source":["<font size=\"5\">\n","    <div class=\"alert alert-warning\" role=\"alert\"> -- Deep Neural Networks -- </div> </font>\n","\n","## **Agenda**\n","\n","1. Deep Neural Networks (DNNs): Introduction\n","\n","2. Recurrent Neural Networks (RNNs)\n","\n","3. **Long Short-Term Memory** (LSTM)\n","---------------------\n","\n","\n","## **References**\n","- [Chollet, F. (2017)](https://sourestdeeds.github.io/pdf/Deep%20Learning%20with%20Python.pdf)\n","\n","- [Haykin, S. (2009)](https://lps.ufrj.br/~caloba/Livros/Haykin2009.pdf)\n","\n","\n","- [Introduction to Machine Learning with Python  book](https://learning.oreilly.com/library/view/introduction-to-machine/9781449369880/)\n"],"metadata":{"id":"SkrP_DZnKUVc"},"id":"SkrP_DZnKUVc"},{"cell_type":"markdown","id":"6e861697","metadata":{"id":"6e861697"},"source":["# **Import libraries**"]},{"cell_type":"code","execution_count":null,"id":"e3ea32c2","metadata":{"ExecuteTime":{"end_time":"2024-10-27T22:37:20.074716Z","start_time":"2024-10-27T22:37:20.071865Z"},"id":"e3ea32c2"},"outputs":[],"source":["### bibliotecas\n","\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import yfinance as yf\n","import tensorflow as tf"]},{"cell_type":"markdown","source":["# **Import Data**"],"metadata":{"id":"UAgRREq9MyWN"},"id":"UAgRREq9MyWN"},{"cell_type":"code","execution_count":null,"id":"206cbbfe","metadata":{"ExecuteTime":{"end_time":"2024-10-27T22:43:17.847712Z","start_time":"2024-10-27T22:43:17.664011Z"},"id":"206cbbfe"},"outputs":[],"source":["### importar dados do yahoo finance\n","\n","\n","AMZN = yf.download('AMZN',\n","                      start='2013-01-01',\n","                      end='2024-09-30',\n","                      progress=False)\n","\n","# AMZN = yf.download('AMZN') for all\n","all_data = AMZN[['Open', 'High', 'Low', 'Close', 'Volume']].round(2)\n","all_data.head(10)\n","print(\"There are \"+ str(all_data[:'2023'].shape[0]) + \" observations in the training data\")\n","print(\"There are \"+ str(all_data['2024':].shape[0]) + \" observations in the test data\")\n","all_data['Close'].plot()\n","\n","\n"]},{"cell_type":"markdown","source":["# **Data Preparation**"],"metadata":{"id":"ypIF9GDKOIdu"},"id":"ypIF9GDKOIdu"},{"cell_type":"code","execution_count":null,"id":"ab1bf561","metadata":{"ExecuteTime":{"end_time":"2024-10-27T22:44:25.000012Z","start_time":"2024-10-27T22:44:24.983606Z"},"id":"ab1bf561"},"outputs":[],"source":["### função que faz a divisão em treino-teste, normaliza os dados\n","### transforma a séries temporal (e os lags) numa dataframe\n","\n","\n","def ts_train_test_normalize(all_data,time_steps,for_periods):\n","    '''\n","    input:\n","      data: dataframe with dates and price data\n","    output:\n","      X_train, y_train: data from 2013/1/1-2023/12/31\n","      X_test:  data from 2024 -\n","      sc:      insantiated MinMaxScaler object fit to the training data\n","    '''\n","    # create training and test set\n","    ts_train = all_data[:'2023'].iloc[:,0:1].values\n","    ts_test  = all_data['2024':].iloc[:,0:1].values\n","    ts_train_len = len(ts_train)\n","    ts_test_len = len(ts_test)\n","\n","    # scale the data\n","    from sklearn.preprocessing import MinMaxScaler\n","    sc = MinMaxScaler(feature_range=(0,1))\n","    ts_train_scaled = sc.fit_transform(ts_train)\n","\n","    # create training data of s samples and t time steps\n","    X_train = []\n","    y_train = []\n","    y_train_stacked = []\n","    for i in range(time_steps,ts_train_len-1):\n","        X_train.append(ts_train_scaled[i-time_steps:i,0])\n","        y_train.append(ts_train_scaled[i:i+for_periods,0])\n","    X_train, y_train = np.array(X_train), np.array(y_train)\n","\n","    # Reshaping X_train for efficient modelling\n","    X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))\n","\n","    inputs = pd.concat((all_data[\"Close\"][:'2023'], all_data[\"Close\"]['2024':]),axis=0).values\n","    inputs = inputs[len(inputs)-len(ts_test) - time_steps:]\n","    inputs = inputs.reshape(-1,1)\n","    inputs  = sc.transform(inputs)\n","\n","    # Preparing X_test\n","    X_test = []\n","    for i in range(time_steps,ts_test_len+time_steps-for_periods):\n","        X_test.append(inputs[i-time_steps:i,0])\n","\n","    X_test = np.array(X_test)\n","    X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n","\n","    return X_train, y_train , X_test, sc\n","\n","X_train, y_train, X_test, sc = ts_train_test_normalize(all_data,5,2)\n","X_train.shape[0],X_train.shape[1]"]},{"cell_type":"code","execution_count":null,"id":"9e3129bf","metadata":{"ExecuteTime":{"end_time":"2024-10-27T22:45:00.236013Z","start_time":"2024-10-27T22:45:00.232025Z"},"id":"9e3129bf"},"outputs":[],"source":["### função para representar graficamente os valores preditos vs teste\n","\n","\n","def actual_pred_plot(preds):\n","    #Plot the actual vs. prediction\n","    actual_pred = pd.DataFrame(columns = ['Close', 'prediction'])\n","    actual_pred['Close'] = all_data.loc['2024':,'Close'][0:len(preds)]\n","    actual_pred['prediction'] = preds[:,0]\n","\n","    from keras.metrics import MeanSquaredError\n","    m = MeanSquaredError()\n","    m.update_state(np.array(actual_pred['Close']),np.array(actual_pred['prediction']))\n","\n","    return (m.result().numpy(), actual_pred.plot() )"]},{"cell_type":"code","execution_count":null,"id":"110f8105","metadata":{"ExecuteTime":{"end_time":"2024-10-27T22:41:25.808468Z","start_time":"2024-10-27T22:41:25.801469Z"},"id":"110f8105"},"outputs":[],"source":["# Convert the 3-D shape of X_train to a data frame so we can see:\n","X_train_see = pd.DataFrame(np.reshape(X_train, (X_train.shape[0],X_train.shape[1])))\n","y_train_see = pd.DataFrame(y_train)\n","pd.concat([X_train_see,y_train_see],axis=1)\n","\n","# Convert the 3-D shape of X_test to a data frame so we can see:\n","X_test_see = pd.DataFrame(np.reshape(X_test, (X_test.shape[0],X_test.shape[1])))\n","pd.DataFrame(X_test_see)\n","\n","print(\"There are \" + str(X_train.shape[0]) + \" samples in the training data\")\n","print(\"There are \" + str(X_test.shape[0]) + \" samples in the test data\")"]},{"cell_type":"markdown","source":["# **LSTM Model - Forecasting**"],"metadata":{"id":"EqHnce2SAyGc"},"id":"EqHnce2SAyGc"},{"cell_type":"code","execution_count":null,"id":"f358f572","metadata":{"ExecuteTime":{"end_time":"2024-10-27T22:50:14.043102Z","start_time":"2024-10-27T22:50:04.408740Z"},"id":"f358f572"},"outputs":[],"source":["## função para LSTM\n","\n","\n","def LSTM_model(X_train, y_train, X_test, sc):\n","    # create a model\n","    from keras.models import Sequential\n","    from keras.layers import Dense, SimpleRNN, GRU, LSTM\n","    from keras.optimizers import SGD, Adam\n","\n","    # The LSTM architecture\n","    my_LSTM_model = Sequential()\n","    my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n","    #my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n","    #my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))\n","    my_LSTM_model.add(LSTM(units=50, activation='tanh')) #Como é a última camada LSTM, a rede não precisa mais de uma sequência de saídas, apenas a saída final.\n","    my_LSTM_model.add(Dense(units=1))\n","\n","    # Compiling\n","    my_LSTM_model.compile(optimizer=Adam(learning_rate=0.01),loss='mean_squared_error')\n","    # Fitting to the training set\n","    my_LSTM_model.fit(X_train,y_train,epochs=50,batch_size=150, verbose=0)\n","\n","    LSTM_prediction = my_LSTM_model.predict(X_test)\n","    LSTM_prediction = sc.inverse_transform(LSTM_prediction)\n","\n","    return my_LSTM_model, LSTM_prediction\n","\n","X_train, y_train, X_test, sc = ts_train_test_normalize(all_data,5,2)\n","my_LSTM_model, LSTM_prediction = LSTM_model(X_train, y_train, X_test, sc)\n","LSTM_prediction[1:10]\n","actual_pred_plot(LSTM_prediction)\n","\n","\n","#Pedir, caso queiram, o vetor das previsões\n","\n","#print(LSTM_prediction)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"e8a335b8","metadata":{"id":"e8a335b8"},"outputs":[],"source":["### Calcular métricas de erro relativas à previsão\n","\n","\n","from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n","\n","y_test = all_data.loc['2024':,'Close'][0:len(LSTM_prediction)].values\n","mae = mean_absolute_error(y_test, LSTM_prediction)\n","print(\"Mean Absolute Error (MAE):\", mae)\n","\n","mape = mean_absolute_percentage_error(y_test, LSTM_prediction)\n","print(f\"Mean Absolute Percentage Error (MAPE): {mape * 100:.3f}%\")"]},{"cell_type":"markdown","source":["## **Exercício 1: Exploração dos Hiperparâmetros**\n","\n","-----------------\n","**OBJETIVO:** Explorar variações em alguns hiperparâmetros e observar como isso impacta o desempenho, a qualidade preditiva e o tempo de execução.\n","\n","----------------------\n","\n","\n","**1. Número de neurónios nas camadas LSTM** (`units`)**:**\n","\n","- **Objetivo:** Aumentar ou diminuir o número de neurônios nas camadas LSTM (por exemplo, tentar `units=10`, `units=100`).\n","  - **Questão:** Testando valores diferentes de `units` na primeira camada `LSTM`, qual o efeito no desempenho e tempo de treino?\n","\n","**2. Número de camadas LSTM:**\n","\n","- **Objetivo:** Ativar uma ou mais camadas LSTM adicionais (descomentando as linhas).\n","  - **Questão:** A adição de camdas melhora o desempenho da rede e/ou introduz problemas de overfitting?\n","\n","**3. Função de ativação:**\n","\n","- **Objetivo:** Alterar a função de ativação da camada LSTM (por exemplo, de `'tanh'` para `'relu'`).\n","  - **Questão:** Testando diferentes funções de ativação, observe como tal afeta a capacidade de aprendizagem e/ou o desempenho.\n","\n","**4. Número de épocas** (`epochs`)**:**\n","\n","- **Objetivo:** Variar o número de épocas (por exemplo, testar `epochs=10`, `epochs=100`).\n","  - **Questão:** Experimentando um número de épocas maior e menor, compare a diferença na qualidade das previsões e no tempo de execução.\n","\n","**5. Algoritmo de otimização:**\n","\n","- **Objetivo:** Experimentar outros otimizadores como `SGD` e `Adam`, e alterar a `learning_rate`.\n","  - **Questão:** Trocando `Adam` por `SGD`, ou experimentar diferentes taxas de aprendizagem (`learning_rate=0.001` e `learning_rate=0.1`) qual(is) o(s) impacto(s) na convergência do modelo.\n","\n","**Notas:**\n","1. O SGD (Stochastic Gradient Descent) é um algoritmo de otimização que ajusta os pesos do modelo para minimizar a função de perda (por exemplo, o erro entre as previsões do modelo e os valores reais). Funciona ajustando gradualmente os pesos da rede em pequenas etapas.\n","\n","Temos, então:\n","  - **Adam:** ajusta automaticamente a velocidade da aprendizagem durante o treino, acelerando quando há confiança na direção e desacelerando para evitar oscilações (o que ajuda a convergir de forma eficiente).\n","\n","  - **SGD:** ajusta os pesos da rede em pequenas etapas a cada lote de dados, permitindo uma aprendizagem mais gradual (pode ser mais lento para convergir).\n","\n","2. A learning rate (taxa de aprendizagem) é um hiperparâmetro fundamental que controla o tamanho dos passos dados pelo otimizador na direção do gradiente. Por outras palavras, a `learning_rate` define a velocidade com que o modelo ajusta seus pesos em resposta ao erro a cada iteração.\n","\n","Temos, então:\n","  - **Learning rate muito alta:** o modelo pode oscilar muito ao redor do ponto ideal de mínimos de erro, sem convergir.\n","  - **Learning rate muito baixa:** o modelo pode demorar muito para convergir, pois os passos são pequenos e o treino pode se tornar-se lento."],"metadata":{"id":"lxqT0mvtUIIH"},"id":"lxqT0mvtUIIH"}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"nbTranslate":{"displayLangs":["*"],"hotkey":"alt-t","langInMainMenu":true,"sourceLang":"en","targetLang":"fr","useGoogleTranslate":true},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[{"file_id":"1hGCyxoEf7OJhaU_xleLDgWwLUqBSPZaM","timestamp":1743981003487},{"file_id":"1nTp7dsMoLLQNps1nVYgt9PYC20vL-unI","timestamp":1743980610224},{"file_id":"112LDK1eqwNEtWTeiFWq41upNTGJsChMn","timestamp":1730236801068}]}},"nbformat":4,"nbformat_minor":5}